{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "import zipfile as zpf\n",
    "import os\n",
    "import re\n",
    "from dateutil.parser import parse as dateparse\n",
    "from dateutil.parser import ParserError\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "soc_boards = glob.glob('../Data/usenet-soc/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [os.path.getsize(board) for board in soc_boards]\n",
    "totsize = np.sum(sizes)\n",
    "props = sizes / totsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['../Data/usenet-soc/soc.culture.african.american.mbox.zip',\n       '../Data/usenet-soc/soc.culture.kuwait.mbox.zip',\n       '../Data/usenet-soc/soc.culture.berber.mbox.zip',\n       '../Data/usenet-soc/soc.culture.african.american.mbox.zip',\n       '../Data/usenet-soc/soc.veterans.mbox.zip',\n       '../Data/usenet-soc/soc.culture.europe.mbox.zip',\n       '../Data/usenet-soc/soc.culture.chile.mbox.zip',\n       '../Data/usenet-soc/soc.culture.german.mbox.zip',\n       '../Data/usenet-soc/soc.culture.spain.mbox.zip',\n       '../Data/usenet-soc/soc.history.war.misc.mbox.zip'], dtype='<U70')"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "np.random.choice(soc_boards, 10, p=props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zpf.ZipFile('../Data/usenet-talk/talk.meow.mbox.zip', 'r') as zp:\n",
    "    raw = zp.open('talk.meow.mbox')\n",
    "\n",
    "def usenet_reader(zp: zpf.ZipExtFile):\n",
    "    outfile = b''\n",
    "    line = True\n",
    "    spot = zp.tell()\n",
    "    while line:\n",
    "        line = zp.readline()\n",
    "        if re.match(b'From [\\d-]+$', line):\n",
    "            if outfile != b'':\n",
    "                yield str(outfile), zp.tell() - spot\n",
    "                spot = zp.tell()\n",
    "            outfile = b''\n",
    "            \n",
    "        outfile += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures = []\n",
    "class Post():\n",
    "    def __init__(self, data):\n",
    "        global failures\n",
    "        raw = str(data.encode('latin1').decode('unicode_escape'))\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                s = re.findall('(?<=[fF]rom: )\\S+@[\\w.]+', raw)[0]\n",
    "            except IndexError:\n",
    "                try:\n",
    "                    s = re.findall('(?<=[fF]rom: )[\\w \\'<>,\".\\-@!+\\\\\\\\]+', raw )[0]\n",
    "                    s = re.findall('(?<=<)[\\S]+@[\\S]+(?=>)', s)[0]\n",
    "                except IndexError:\n",
    "                    s = ''\n",
    "            self.source = s\n",
    "\n",
    "            d = re.findall('(?<=[Dd]ate: )[\\w ,.:]+', raw)[0]\n",
    "            while True:\n",
    "                try:\n",
    "                    self.date = dateparse(d)\n",
    "                    break\n",
    "                except ParserError:\n",
    "                    d = d[:-4]\n",
    "                    if d == '':\n",
    "                        break\n",
    "\n",
    "            ngroups = re.findall('(?<=[Nn]ewsgroups: )[\\w ,.]+', raw )[0].split(',')\n",
    "\n",
    "            self.newsgroups = ngroups\n",
    "\n",
    "            s = re.findall('(?<=[Ss]ubject: )[[\\]\\S .,:-]+', raw)[0]\n",
    "            self.subject = s\n",
    "\n",
    "            try:\n",
    "                mid = re.findall('(?<=[mM]essage-[iI][dD]: )[\\S]+(?=\\\\n)', raw)[0]\n",
    "                self.message_id = mid\n",
    "            except IndexError as e:\n",
    "                failures.append(e.__traceback__)\n",
    "                self.message_id = f'no_mid_{len(failures)}'\n",
    "\n",
    "            lines = [(len(x) > 0 and ':' not in x) for x in raw.split('\\n')[1:]]\n",
    "            self.body = '\\n'.join(raw.split('\\n')[np.argmax(lines)+1:])\n",
    "        except IndexError as e:\n",
    "            self.message_id = f'no_mid_{len(failures)}'\n",
    "            failures.append(e.__traceback__)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Post ID: {self.message_id}'\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'Post from: {self.source} with subject: {self.subject}'\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.message_id == other.message_id\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.message_id)\n",
    "\n",
    "class Newsgroup(set):\n",
    "    def __init__(self, name, posts=[], loc='auto'):\n",
    "        super().__init__(self)\n",
    "        hierarchy = name.split('.')[0]\n",
    "        if loc == 'auto':\n",
    "            if not os.path.exists(f'../Data/{hierarchy}'):\n",
    "                loc = '.'\n",
    "            else:\n",
    "                loc = f'../Data/{hierarchy}'\n",
    "\n",
    "        self.file_name = loc + '/' + name + '.zip'\n",
    "        self.name = name\n",
    "        self.load()\n",
    "        for post in posts:\n",
    "            self.add(post)\n",
    "    \n",
    "    def save(self):\n",
    "        with zpf.ZipFile(self.file_name, 'w') as f:\n",
    "            with f.open(f'{self.name}.pkl', 'w') as jar:\n",
    "                pickle.dump(self, jar)\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            with zpf.ZipFile(self.file_name, 'r') as f:\n",
    "                with f.open(f'{self.name}.pkl', 'r') as jar:\n",
    "                    oldset = pickle.load(jar)\n",
    "                    for post in oldset:\n",
    "                        self.add(post)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_mbox(cls, file_name, rm=False, save=True):\n",
    "        name = file_name.split('/')[-1][:-9]\n",
    "        hierarchy = name.split('.')[0]\n",
    "        if not os.path.exists(f'../Data/{hierarchy}'):\n",
    "            os.mkdir(f'../Data/{hierarchy}')\n",
    "        self = cls(name, loc=f'../Data/{hierarchy}')\n",
    "        with zpf.ZipFile(file_name, 'r') as zp:\n",
    "            raw = zp.open(f'{name}.mbox')\n",
    "            raw.seek(0, 2)\n",
    "            size = raw.tell()\n",
    "            raw.seek(0,0)\n",
    "\n",
    "        post_iterator = usenet_reader(raw)\n",
    "        with tqdm(usenet_reader(raw), total=size) as pbar:\n",
    "            pbar.set_description(f'Loading {name}...')\n",
    "            for post, line in usenet_reader(raw):\n",
    "                self.add(Post(post))\n",
    "                pbar.update(line)\n",
    "        if save:\n",
    "            self.save()\n",
    "\n",
    "        if rm:\n",
    "            os.remove(file_name)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    @classmethod\n",
    "    def from_hierarchy(cls, hierarchy):\n",
    "        toplevel = hierarchy.split('.')[0]\n",
    "        big_group = cls(hierarchy)\n",
    "        all_boards = glob.glob(f'../Data/usenet-{toplevel}/{hierarchy}*')\n",
    "        for group in all_boards:\n",
    "            big_group |= Newsgroup.from_mbox(group, save=False)\n",
    "        return big_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "27403"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "aviation = Newsgroup.from_hierarchy('rec.aviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitvenvvenv719d8013fdc440a1be919f9cf5f2dde2",
   "display_name": "Python 3.8.2 64-bit ('venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}